package com.firzzle.llm.service;

import com.fasterxml.jackson.core.type.TypeReference;
import com.fasterxml.jackson.databind.ObjectMapper;
import com.firzzle.llm.client.*;
import com.firzzle.llm.dto.*;
import com.firzzle.llm.prompt.*;
import com.firzzle.llm.repository.TestRepository;
import com.firzzle.llm.entity.*;
import com.firzzle.llm.util.*;

import lombok.RequiredArgsConstructor;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.beans.factory.annotation.Autowired;


import org.springframework.scheduling.annotation.Async;
import org.springframework.stereotype.Service;


import java.time.LocalDateTime;
import java.util.*;
import java.util.concurrent.CompletableFuture;
import java.util.stream.Collectors;

@Service
@RequiredArgsConstructor
public class LlmService {

    private final OpenAiClient openAiClient;
    private final QdrantClient qdrantClient;
    private final SummaryPrompt summaryPrompt;
    private final RunnigChatPrompt runningChatPrompt;
    private final EmbeddingService embeddingService;
    private final TestRepository testRepository;

    private static final Logger logger = LoggerFactory.getLogger(LlmService.class);
    // ì „ì²´ ìë§‰ ì½˜í…ì¸ ë¥¼ ìš”ì•½í•˜ëŠ” ë¹„ë™ê¸° í•¨ìˆ˜
    @Async
    public CompletableFuture<String> summarizeContents(SummaryRequest request) {
        String content = request.getContent();
        List<String> scriptLines = Arrays.asList(content.split("\n"));

        logger.info("ğŸš€ ì „ì²´ ìš”ì•½ ì‹œì‘");

        return extractTimeLine(content)
            .thenCompose(timelines -> summarizeByChunks(timelines, scriptLines))
            .thenApply(summary -> {
            	logger.info(summary);
                saveSummaryToDbAndVector(summary, scriptLines); // âœ… ì™¸ë¶€ í•¨ìˆ˜ë¡œ ë¶„ë¦¬
                return summary;
            })
            .exceptionally(e -> {
                logger.error("âŒ ì „ì²´ ìš”ì•½ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜", e);
                return "GPT ì‘ë‹µ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.";
            });
    }
    
    // ì „ì²´ ìë§‰ í…ìŠ¤íŠ¸ì—ì„œ ì£¼ìš” ëŒ€ì£¼ì œë¥¼ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜
    @Async
    private CompletableFuture<List<TimeLine>> extractTimeLine(String content) {
        String instruction = summaryPrompt.createInstruction();
    
        return openAiClient.getChatCompletionAsync(instruction, content, ModelType.TIMELINE)
                .thenApply(response -> {
                    try {
                        ObjectMapper mapper = new ObjectMapper();
                        String cleaned = ScriptUtils.extractJsonOnly(response);
                        logger.info(cleaned);
                        return mapper.readValue(cleaned, new TypeReference<List<TimeLine>>() {});
                    } catch (Exception e) {
                        logger.error("âŒ ëŒ€ì£¼ì œ JSON íŒŒì‹± ì‹¤íŒ¨: {}", response, e);
                        throw new RuntimeException("ëŒ€ì£¼ì œ íŒŒì‹± ì‹¤íŒ¨", e);
                    }
                });
    }
    
    // ì£¼ìš” í† í”½ë³„ë¡œ ìë§‰ì„ ë‚˜ëˆ„ì–´ ìš”ì•½ ìš”ì²­ì„ ë³´ë‚´ëŠ” í•¨ìˆ˜
    @Async
    private CompletableFuture<String> summarizeByChunks(List<TimeLine> topics, List<String> scriptLines) {
        List<CompletableFuture<String>> futures = new ArrayList<>();
        
        for (int i = 0; i < topics.size() - 1; i++) {
            TimeLine timeA = topics.get(i);
            TimeLine timeB = topics.get(i + 1);
            String start = timeA.getTime();
            String end = timeB.getTime();

            String rawText = ScriptUtils.extractChunkText(scriptLines, start, end);

            if (rawText.strip().isEmpty()) {
                logger.warn("âš ï¸ {}~{} ë²”ìœ„ì— ìë§‰ì´ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœ€", start, end);
                continue;
            }

            String chunkText = String.format(
            	    start, rawText
            	);
            logger.info(chunkText+"\n\n");
            String instruction = summaryPrompt.createInstruction2();
            futures.add(openAiClient.getChatCompletionAsync(instruction, chunkText, ModelType.SUMMARY));
        }

        // ë§ˆì§€ë§‰ êµ¬ê°„ (ëê¹Œì§€)
        if (!topics.isEmpty()) {
            TimeLine lastTopic = topics.get(topics.size() - 1);
            String start = lastTopic.getTime();
            String end = "99999";
            String rawText = ScriptUtils.extractChunkText(scriptLines, start, end);

            if (!rawText.strip().isEmpty()) {
                String chunkText = String.format(
                    start, rawText
                );
                futures.add(openAiClient.getChatCompletionAsync(summaryPrompt.createInstruction2(), chunkText, ModelType.SUMMARY));
            }
        }

        return CompletableFuture
            .allOf(futures.toArray(new CompletableFuture[0]))
            .thenApply(v -> futures.stream()
                .map(CompletableFuture::join)
                .collect(Collectors.joining(",\n", "[", "]")));
    }
    
    
    private void saveSummaryToDbAndVector(String summary, List<String> scriptLines) {
        // ë²¡í„° ì €ì¥
//        List<Float> vector = embeddingService.embed(summary);
        
//		qdrantClient.upsertVector(QdrantCollections.SCRIPT, uuid.hashCode(), vector, summary)
//		    .doOnError(e -> logger.error("ì—…ì„œíŠ¸ ì‹¤íŒ¨", e))
//		    .subscribe(); // ë¹„ë™ê¸° ì²˜ë¦¬
    }


    // RAG ê¸°ë°˜ ì‹¤ì‹œê°„ ëŒ€í™” ì‘ë‹µ ìƒì„± (ìµœê·¼ ëŒ€í™” ë§¥ë½ ì—†ì´ contextë§Œ í™œìš©)
    @Async
    public CompletableFuture<String> runningChat(RunningChatRequest request) {
        String question = request.getQuestion();
        List<Float> vector = embeddingService.embed(question);
        CompletableFuture<List<String>> contents = qdrantClient.searchWithPayload(QdrantCollections.SCRIPT, vector, 10, 0.3).toFuture();

        String context = ((Collection<String>) contents).stream().limit(5).collect(Collectors.joining("\n"));
        String Prompt = runningChatPrompt.createPrompt(question, "", context);
        String instruction = runningChatPrompt.createInstruction();

        // TODO: ì‹¤ì œ GPT í˜¸ì¶œ í•„ìš”
        return null;
    }

    // TEST ì»¬ë ‰ì…˜ì„ ê¸°ë°˜ìœ¼ë¡œ GPT ë‹µë³€ì„ ìƒì„±í•˜ëŠ” í…ŒìŠ¤íŠ¸ìš© ë¹„ë™ê¸° í•¨ìˆ˜
    @Async
    public CompletableFuture<String> testGptResponse(String question) {
        long startTime = System.nanoTime();
        logger.info("\uD83D\uDE80 GPT ì§ˆë¬¸ ìˆ˜ì‹ : {}", question);

        return CompletableFuture.supplyAsync(() -> embeddingService.embed(question))
            .thenCompose(vector -> qdrantClient.searchWithPayload(QdrantCollections.TEST, vector, 10, 0.3).toFuture())
            .thenCompose(contents -> {
                String context = contents.stream().limit(5).collect(Collectors.joining("\n"));
                String prompt = "ë‹¤ìŒ ë¬¸ë§¥ì„ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µí•´ì£¼ì„¸ìš”:\n" + context + "\n\nì§ˆë¬¸: " + question;
                String instruction = "ë¬¸ë§¥ì„ ê¸°ë°˜ìœ¼ë¡œ ëª…í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.";

                return openAiClient.getChatCompletionAsync(instruction, prompt, ModelType.SUMMARY);
            })
            .thenApply(result -> {
                long endTime = System.nanoTime();
                logger.info("\u2705 GPT ì‘ë‹µ ì™„ë£Œ ({}ms)", (endTime - startTime) / 1_000_000);
                return result;
            })
            .exceptionally(e -> {
                logger.error("\u274C GPT ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜", e);
                return "GPT ì‘ë‹µ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.";
            });
    }

    

    

    // ìƒˆ ì½˜í…ì¸ ë¥¼ ë²¡í„°í™”í•˜ê³  Qdrant ë° DBì— ì €ì¥
    public void register(Integer id, String content) {
        List<Float> vector = embeddingService.embed(content);

        testRepository.save(TestEntity.builder()
            .id(id)
            .content(content)
            .createdAt(LocalDateTime.now())
            .build());

        vector.forEach(v -> {
            if (v == null || v.isNaN() || v.isInfinite()) {
                logger.error("\u274C ë²¡í„° ê°’ ì˜¤ë¥˜: {}", v);
            }
        });

        qdrantClient.upsertVector(QdrantCollections.TEST, id, vector, content).block();
    }
}
