package com.firzzle.llm.service;

import java.util.List;
import java.util.concurrent.CompletableFuture;
import java.util.stream.Collectors;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.scheduling.annotation.Async;
import org.springframework.stereotype.Service;
import org.springframework.transaction.annotation.Transactional;

import com.firzzle.llm.client.OpenAiClient;
import com.firzzle.llm.dto.ChatCompletionRequest;
import com.firzzle.llm.dto.learningChatRequestDTO;
import com.firzzle.llm.prompt.PromptFactory;
import com.firzzle.llm.util.QdrantCollections;

import lombok.RequiredArgsConstructor;

@Service
@RequiredArgsConstructor
public class learningChatService {
    private final OpenAiClient openAiClient;
    private final EmbeddingService embeddingService;
    private final RagService ragService;
    private final PromptFactory promptFactory;

    private static final Logger logger = LoggerFactory.getLogger(RegistrationService.class);
	
	 // RAG ê¸°ë°˜ ì‹¤ì‹œê°„ ëŒ€í™” ì‘ë‹µ ìƒì„± (ìµœê·¼ ëŒ€í™” ë§¥ë½ ì—†ì´ contextë§Œ í™œìš©)
    @Async
    @Transactional
    public CompletableFuture<String> learningChat(Long contentSeq, learningChatRequestDTO request, String userId) {
        String question = request.getQuestion();
        logger.info("ğŸ“¥ [learningChat ì‹œì‘] contentSeq={}, userId={}, question={}", contentSeq, userId, question);

        List<Float> vector = embeddingService.embed(question);

        return ragService.searchTopPayloadsByContentSeq(QdrantCollections.SCRIPT, vector, contentSeq)
                .toFuture()
                .thenCompose(contents -> {
                    logger.debug("ğŸ” [ë²¡í„° ê²€ìƒ‰ ê²°ê³¼] top contents count={}", contents.size());

                    String context = contents.stream().limit(5).collect(Collectors.joining("\n"));

                    if (context.isEmpty()) {
                        logger.info("âš ï¸ [context ì—†ìŒ] ê¸°ë³¸ ì‘ë‹µ ë°˜í™˜");
                        return CompletableFuture.completedFuture(
                                "í•´ë‹¹ ë‚´ìš©ì€ ì˜ìƒì—ì„œ ì–¸ê¸‰ë˜ì§€ ì•Šì•˜ì–´ìš”. ë‹¤ë¥¸ ì§ˆë¬¸ì´ ìˆìœ¼ì‹ ê°€ìš”? ê¶ê¸ˆí•œ ì ì„ ë§ì”€í•´ ì£¼ì‹œë©´ ìµœëŒ€í•œ ë„ì™€ë“œë¦´ê²Œìš”!"
                        );
                    }

                    ChatCompletionRequest chatRequest = promptFactory.createLearningChatRequest(question, context);
                    logger.debug("ğŸ“¤ [OpenAI ìš”ì²­ ì „] ìƒì„±ëœ prompt context ì¼ë¶€=\n{}", context.substring(0, Math.min(context.length(), 300)));

                    return openAiClient.getChatCompletionAsync(chatRequest);
                })
                .exceptionally(e -> {
                    logger.error("âŒ learningChat ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜", e);
                    return "ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.";
                });
    }
}
